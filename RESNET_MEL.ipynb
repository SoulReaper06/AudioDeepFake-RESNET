{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(file_path, max_time_steps=109, sample_rate=22050, duration=3, n_mels=128):\n",
    "    audio, _ = librosa.load(file_path, sr=sample_rate, duration=duration)\n",
    "\n",
    "    # Extract Mel spectrogram using librosa\n",
    "    mel_spectrogram = librosa.feature.melspectrogram(y=audio, sr=sample_rate, n_mels=n_mels)\n",
    "    mel_spectrogram = librosa.power_to_db(mel_spectrogram, ref=np.max)\n",
    "\n",
    "    # Ensure all spectrograms have the same width (time steps)\n",
    "    if mel_spectrogram.shape[1] < max_time_steps:\n",
    "        mel_spectrogram = np.pad(mel_spectrogram, ((0, 0), (0, max_time_steps - mel_spectrogram.shape[1])), mode='constant')\n",
    "    else:\n",
    "        mel_spectrogram = mel_spectrogram[:, :max_time_steps]\n",
    "\n",
    "    return mel_spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your file paths and constants\n",
    "TRAINING_LABEL = '/data/common_source/datasets/asvpoof-2019-dataset/LA/LA/ASVspoof2019_LA_cm_protocols/ASVspoof2019.LA.cm.train.trn.txt'\n",
    "TRAINING_DATA = '/data/common_source/datasets/asvpoof-2019-dataset/LA/LA/ASVspoof2019_LA_train/flac'\n",
    "VALIDATION_DATA = '/data/common_source/datasets/asvpoof-2019-dataset/LA/LA/ASVspoof2019_LA_dev/flac'\n",
    "VALIDATION_LABEL = '/data/common_source/datasets/asvpoof-2019-dataset/LA/LA/ASVspoof2019_LA_cm_protocols/ASVspoof2019.LA.cm.dev.trn.txt'\n",
    "TEST_LABEL = '/data/common_source/datasets/asvpoof-2019-dataset/LA/LA/ASVspoof2019_LA_cm_protocols/ASVspoof2019.LA.cm.test.trn.txt'\n",
    "TEST_DATA = '/data/common_source/datasets/asvpoof-2019-dataset/LA/LA/ASVspoof2019_LA_test/flac'\n",
    "SAMPLE_RATE = 22050  # Adjust if your sample rate is different\n",
    "DURATION = 3  # Adjust the duration of your audio samples\n",
    "N_MELS = 128  # Adjust the number of mel filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load labels for training Data\n",
    "labels = {}\n",
    "\n",
    "with open(TRAINING_LABEL, 'r') as label_file:\n",
    "    lines = label_file.readlines()\n",
    "\n",
    "for line in lines:\n",
    "    parts = line.strip().split()\n",
    "    file_name = parts[1]\n",
    "    label = 1 if parts[-1] == \"bonafide\" else 0\n",
    "    labels[file_name] = label\n",
    "\n",
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "max_time_steps = 109  # Define the maximum time steps for your model\n",
    "\n",
    "for file_name, label in labels.items():\n",
    "    file_path = os.path.join(TRAINING_DATA, file_name + \".flac\")\n",
    "\n",
    "    # Load audio file using librosa\n",
    "    audio, _ = librosa.load(file_path, sr=SAMPLE_RATE, duration=DURATION)\n",
    "\n",
    "    # Extract Mel spectrogram using librosa\n",
    "    mel_spectrogram = librosa.feature.melspectrogram(y=audio, sr=SAMPLE_RATE, n_mels=N_MELS)\n",
    "    mel_spectrogram = librosa.power_to_db(mel_spectrogram, ref=np.max)\n",
    "\n",
    "    # Ensure all spectrograms have the same width (time steps)\n",
    "    if mel_spectrogram.shape[1] < max_time_steps:\n",
    "        mel_spectrogram = np.pad(mel_spectrogram, ((0, 0), (0, max_time_steps - mel_spectrogram.shape[1])), mode='constant')\n",
    "    else:\n",
    "        mel_spectrogram = mel_spectrogram[:, :max_time_steps]\n",
    "\n",
    "    X_train.append(mel_spectrogram)\n",
    "    y_train.append(label)\n",
    "\n",
    "X_train = np.array(X)\n",
    "y_train = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load labels for evaluation Data\n",
    "labels = {}\n",
    "\n",
    "with open(VALIDATION_LABEL, 'r') as label_file:\n",
    "    lines = label_file.readlines()\n",
    "\n",
    "for line in lines:\n",
    "    parts = line.strip().split()\n",
    "    file_name = parts[1]\n",
    "    label = 1 if parts[-1] == \"bonafide\" else 0\n",
    "    labels[file_name] = label\n",
    "\n",
    "X_dev = []\n",
    "y_dev = []\n",
    "\n",
    "max_time_steps = 109  # Define the maximum time steps for your model\n",
    "\n",
    "for file_name, label in labels.items():\n",
    "    file_path = os.path.join(VALIDATION_DATA, file_name + \".flac\")\n",
    "\n",
    "    # Load audio file using librosa\n",
    "    audio, _ = librosa.load(file_path, sr=SAMPLE_RATE, duration=DURATION)\n",
    "\n",
    "    # Extract Mel spectrogram using librosa\n",
    "    mel_spectrogram = librosa.feature.melspectrogram(y=audio, sr=SAMPLE_RATE, n_mels=N_MELS)\n",
    "    mel_spectrogram = librosa.power_to_db(mel_spectrogram, ref=np.max)\n",
    "\n",
    "    # Ensure all spectrograms have the same width (time steps)\n",
    "    if mel_spectrogram.shape[1] < max_time_steps:\n",
    "        mel_spectrogram = np.pad(mel_spectrogram, ((0, 0), (0, max_time_steps - mel_spectrogram.shape[1])), mode='constant')\n",
    "    else:\n",
    "        mel_spectrogram = mel_spectrogram[:, :max_time_steps]\n",
    "\n",
    "    X_dev.append(mel_spectrogram)\n",
    "    y_dev.append(label)\n",
    "\n",
    "X_dev = np.array(X_dev)\n",
    "y_dev = np.array(y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load labels for testing Data\n",
    "labels = {}\n",
    "\n",
    "with open(TEST_LABEL, 'r') as label_file:\n",
    "    lines = label_file.readlines()\n",
    "\n",
    "for line in lines:\n",
    "    parts = line.strip().split()\n",
    "    file_name = parts[1]\n",
    "    label = 1 if parts[-1] == \"bonafide\" else 0\n",
    "    labels[file_name] = label\n",
    "\n",
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "max_time_steps = 109  # Define the maximum time steps for your model\n",
    "\n",
    "for file_name, label in labels.items():\n",
    "    file_path = os.path.join(TEST_DATA, file_name + \".flac\")\n",
    "\n",
    "    # Load audio file using librosa\n",
    "    audio, _ = librosa.load(file_path, sr=SAMPLE_RATE, duration=DURATION)\n",
    "\n",
    "    # Extract Mel spectrogram using librosa\n",
    "    mel_spectrogram = librosa.feature.melspectrogram(y=audio, sr=SAMPLE_RATE, n_mels=N_MELS)\n",
    "    mel_spectrogram = librosa.power_to_db(mel_spectrogram, ref=np.max)\n",
    "\n",
    "    # Ensure all spectrograms have the same width (time steps)\n",
    "    if mel_spectrogram.shape[1] < max_time_steps:\n",
    "        mel_spectrogram = np.pad(mel_spectrogram, ((0, 0), (0, max_time_steps - mel_spectrogram.shape[1])), mode='constant')\n",
    "    else:\n",
    "        mel_spectrogram = mel_spectrogram[:, :max_time_steps]\n",
    "\n",
    "    X_test.append(mel_spectrogram)\n",
    "    y_test.append(label)\n",
    "\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape input data to match the required input shape for ResNet\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], X_train.shape[2], 1))\n",
    "\n",
    "# Reshape input data to match the required input shape for ResNet\n",
    "X_dev = X_dev.reshape((X_dev.shape[0], X_dev.shape[1], X_dev.shape[2], 1))\n",
    "\n",
    "# Define input shape and number of classes\n",
    "input_shape = X_train[0].shape\n",
    "num_classes = 2  # Assuming you have two classes (0 and 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Over sample\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "print(X_train.shape)\n",
    "# Flatten the X_train data if needed\n",
    "X_train_flattened = X_train.reshape(X_train.shape[0], -1)\n",
    "\n",
    "# Instantiate the SMOTE object\n",
    "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "\n",
    "# Apply SMOTE to the dataset\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train_flattened, y_train)\n",
    "\n",
    "print(X_resampled.shape)\n",
    "\n",
    "# Reshape X_resampled to match the shape of the original X_train\n",
    "X_resampled_reshaped = X_resampled.reshape(-1, 13, 109)\n",
    "\n",
    "\n",
    "print(X_resampled_reshaped.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the ResNet block\n",
    "def resnet_block(x, filters, kernel_size=3, stride=1, conv_shortcut=False):\n",
    "    shortcut = x\n",
    "    if conv_shortcut:\n",
    "        shortcut = layers.Conv2D(filters, 1, strides=stride)(shortcut)\n",
    "        shortcut = layers.BatchNormalization()(shortcut)\n",
    "\n",
    "    x = layers.Conv2D(filters, kernel_size, strides=stride, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "\n",
    "    x = layers.Conv2D(filters, kernel_size, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    x = layers.add([x, shortcut])\n",
    "    x = layers.Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "# Build the ResNet model\n",
    "def build_resnet(input_shape, num_classes):\n",
    "    input_tensor = layers.Input(shape=input_shape)\n",
    "\n",
    "    x = layers.Conv2D(64, 7, strides=2, padding='same')(input_tensor)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.MaxPooling2D(3, strides=2, padding='same')(x)\n",
    "\n",
    "    # ResNet blocks\n",
    "    for size in [64, 128, 256, 512]:\n",
    "        x = resnet_block(x, size, conv_shortcut=True)\n",
    "        x = resnet_block(x, size)\n",
    "\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = models.Model(inputs=input_tensor, outputs=x, name='resnet_model')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-13 02:32:20.587112: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-13 02:32:21.376269: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22834 MB memory:  -> device: 0, name: NVIDIA TITAN RTX, pci bus id: 0000:1a:00.0, compute capability: 7.5\n",
      "2023-11-13 02:32:21.376878: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 22757 MB memory:  -> device: 1, name: NVIDIA TITAN RTX, pci bus id: 0000:68:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "# Build ResNet model\n",
    "resnet_model = build_resnet(input_shape, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "resnet_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet_model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 128, 109, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 64, 55, 64)   3200        ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 64, 55, 64)  256         ['conv2d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 64, 55, 64)   0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 32, 28, 64)   0           ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 32, 28, 64)   36928       ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 32, 28, 64)  256         ['conv2d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 32, 28, 64)   0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 32, 28, 64)   36928       ['activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 32, 28, 64)   4160        ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 32, 28, 64)  256         ['conv2d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 32, 28, 64)  256         ['conv2d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 32, 28, 64)   0           ['batch_normalization_3[0][0]',  \n",
      "                                                                  'batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 32, 28, 64)   0           ['add[0][0]']                    \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 32, 28, 64)   36928       ['activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 32, 28, 64)  256         ['conv2d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 32, 28, 64)   0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 32, 28, 64)   36928       ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 32, 28, 64)  256         ['conv2d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 32, 28, 64)   0           ['batch_normalization_5[0][0]',  \n",
      "                                                                  'activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 32, 28, 64)   0           ['add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 32, 28, 128)  73856       ['activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 32, 28, 128)  512        ['conv2d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 32, 28, 128)  0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 32, 28, 128)  147584      ['activation_5[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 32, 28, 128)  8320        ['activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 32, 28, 128)  512        ['conv2d_8[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 32, 28, 128)  512        ['conv2d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 32, 28, 128)  0           ['batch_normalization_8[0][0]',  \n",
      "                                                                  'batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 32, 28, 128)  0           ['add_2[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 32, 28, 128)  147584      ['activation_6[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 32, 28, 128)  512        ['conv2d_9[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 32, 28, 128)  0           ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 32, 28, 128)  147584      ['activation_7[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 32, 28, 128)  512        ['conv2d_10[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_3 (Add)                    (None, 32, 28, 128)  0           ['batch_normalization_10[0][0]', \n",
      "                                                                  'activation_6[0][0]']           \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 32, 28, 128)  0           ['add_3[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 32, 28, 256)  295168      ['activation_8[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 32, 28, 256)  1024       ['conv2d_12[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 32, 28, 256)  0           ['batch_normalization_12[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 32, 28, 256)  590080      ['activation_9[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 32, 28, 256)  33024       ['activation_8[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 32, 28, 256)  1024       ['conv2d_13[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 32, 28, 256)  1024       ['conv2d_11[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_4 (Add)                    (None, 32, 28, 256)  0           ['batch_normalization_13[0][0]', \n",
      "                                                                  'batch_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " activation_10 (Activation)     (None, 32, 28, 256)  0           ['add_4[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 32, 28, 256)  590080      ['activation_10[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 32, 28, 256)  1024       ['conv2d_14[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_11 (Activation)     (None, 32, 28, 256)  0           ['batch_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 32, 28, 256)  590080      ['activation_11[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 32, 28, 256)  1024       ['conv2d_15[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_5 (Add)                    (None, 32, 28, 256)  0           ['batch_normalization_15[0][0]', \n",
      "                                                                  'activation_10[0][0]']          \n",
      "                                                                                                  \n",
      " activation_12 (Activation)     (None, 32, 28, 256)  0           ['add_5[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 32, 28, 512)  1180160     ['activation_12[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_17 (BatchN  (None, 32, 28, 512)  2048       ['conv2d_17[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_13 (Activation)     (None, 32, 28, 512)  0           ['batch_normalization_17[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, 32, 28, 512)  2359808     ['activation_13[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 32, 28, 512)  131584      ['activation_12[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_18 (BatchN  (None, 32, 28, 512)  2048       ['conv2d_18[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, 32, 28, 512)  2048       ['conv2d_16[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_6 (Add)                    (None, 32, 28, 512)  0           ['batch_normalization_18[0][0]', \n",
      "                                                                  'batch_normalization_16[0][0]'] \n",
      "                                                                                                  \n",
      " activation_14 (Activation)     (None, 32, 28, 512)  0           ['add_6[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)             (None, 32, 28, 512)  2359808     ['activation_14[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_19 (BatchN  (None, 32, 28, 512)  2048       ['conv2d_19[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_15 (Activation)     (None, 32, 28, 512)  0           ['batch_normalization_19[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)             (None, 32, 28, 512)  2359808     ['activation_15[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_20 (BatchN  (None, 32, 28, 512)  2048       ['conv2d_20[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_7 (Add)                    (None, 32, 28, 512)  0           ['batch_normalization_20[0][0]', \n",
      "                                                                  'activation_14[0][0]']          \n",
      "                                                                                                  \n",
      " activation_16 (Activation)     (None, 32, 28, 512)  0           ['add_7[0][0]']                  \n",
      "                                                                                                  \n",
      " global_average_pooling2d (Glob  (None, 512)         0           ['activation_16[0][0]']          \n",
      " alAveragePooling2D)                                                                              \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 2)            1026        ['global_average_pooling2d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 11,190,082\n",
      "Trainable params: 11,180,354\n",
      "Non-trainable params: 9,728\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Display the model summary\n",
    "resnet_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-13 02:33:20.498318: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8600\n",
      "2023-11-13 02:33:21.778213: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "635/635 [==============================] - 63s 92ms/step - loss: 0.1717 - accuracy: 0.9307 - val_loss: 7.0544 - val_accuracy: 0.3349\n",
      "Epoch 2/10\n",
      "635/635 [==============================] - 58s 91ms/step - loss: 0.0806 - accuracy: 0.9695 - val_loss: 0.5567 - val_accuracy: 0.8989\n",
      "Epoch 3/10\n",
      "635/635 [==============================] - 58s 92ms/step - loss: 0.0522 - accuracy: 0.9814 - val_loss: 0.3153 - val_accuracy: 0.9427\n",
      "Epoch 4/10\n",
      "635/635 [==============================] - 58s 92ms/step - loss: 0.0306 - accuracy: 0.9901 - val_loss: 24.8457 - val_accuracy: 0.1675\n",
      "Epoch 5/10\n",
      "635/635 [==============================] - 59s 92ms/step - loss: 0.0332 - accuracy: 0.9891 - val_loss: 0.0201 - val_accuracy: 0.9933\n",
      "Epoch 6/10\n",
      "635/635 [==============================] - 59s 92ms/step - loss: 0.0199 - accuracy: 0.9938 - val_loss: 1.8837 - val_accuracy: 0.8599\n",
      "Epoch 7/10\n",
      "635/635 [==============================] - 59s 93ms/step - loss: 0.0184 - accuracy: 0.9943 - val_loss: 0.6738 - val_accuracy: 0.9005\n",
      "Epoch 8/10\n",
      "635/635 [==============================] - 59s 93ms/step - loss: 0.0175 - accuracy: 0.9947 - val_loss: 0.4634 - val_accuracy: 0.9119\n",
      "Epoch 9/10\n",
      "635/635 [==============================] - 59s 93ms/step - loss: 0.0155 - accuracy: 0.9953 - val_loss: 0.3726 - val_accuracy: 0.9110\n",
      "Epoch 10/10\n",
      "635/635 [==============================] - 59s 93ms/step - loss: 0.0144 - accuracy: 0.9947 - val_loss: 15.1117 - val_accuracy: 0.9005\n",
      "159/159 [==============================] - 5s 31ms/step - loss: 15.1117 - accuracy: 0.9005\n",
      "Test Loss: 15.1117, Test Accuracy: 90.05%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# # Split the data into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "epochs = 100  # Adjust the number of epochs as needed\n",
    "\n",
    "resnet_model.fit(X_train, y_train, epochs=epochs, validation_data=(X_dev, y_dev))\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "loss, accuracy = resnet_model.evaluate(X_test, y_test)\n",
    "print(f'Test Loss: {loss:.4f}, Test Accuracy: {accuracy * 100:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newconda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18 | packaged by conda-forge | (main, Aug 30 2023, 03:49:32) \n[GCC 12.3.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "2df73002193cefbfa9243a6efa2b74af79e3047145117f20857a75b11408ac59"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
